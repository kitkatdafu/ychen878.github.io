<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ML on mrr1vfe</title><link>https://www.reidy.icu/tags/ml/</link><description>Recent content in ML on mrr1vfe</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Reid Chen</copyright><lastBuildDate>Tue, 19 Oct 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://www.reidy.icu/tags/ml/index.xml" rel="self" type="application/rss+xml"/><item><title>K-means in Python</title><link>https://www.reidy.icu/posts/k-means/</link><pubDate>Tue, 19 Oct 2021 00:00:00 +0000</pubDate><guid>https://www.reidy.icu/posts/k-means/</guid><description>K-means There are two major steps in the K-means algorithm. The first one is to calculate the representatives (centroids) of a given partition. The second one is to find the partition based on the representatives.
Inputs Suppose we have a dataset looks like this:
1dataset = np.array([[5, 6], 2 [6, 5], 3 [0, 1], 4 [1, 0], 5 [3, 3]]) Each row in this dataset matrix is an observation and each column in this matrix represents a feature.</description></item></channel></rss>