#+TITLE: Memory and Cache Review
#+AUTHOR: Reid Chen
#+EMAIL: reid@cs.wisc.edu
#+DATE: <2019-10-11 Fri>
#+tags[]: C Cache Memory
#+categories[]: CS OS
* Locality
** Principle of locality
   Programs tend to use data and instructions with addresses near or equal to those they have recently used.
- temporal locality :: Recently referenced items are likely to be referenced again in the near future.
- spatial locality :: Items with nearby addresses tend to be referenced close together in time.
** Locality Example
   #+BEGIN_SRC C
   sum = 0;
   for (int i = 0; i < n; i++)
       sum += a[i];
   return sum;
   #+END_SRC
*** Data References
    - Reference array elements in succession (stride - 1 reference pattern). *spatial locality*
    - Reference variable ==sum== each iteration. *temporal locality*
*** Instructions References
    - Reference instructions in sequence. *spatial locality*
    - Cycle through loop repeatedly. *temporal locality*
* Cache
- cache :: A smaller, faster storage device that acts as a staging area for a subset of the data in a larger, slower device.
** Fundamental idea of a memory hierarchy
   For each k, the faster, smaller device at level k servers as a cache for the larger, slower device at level k + 1.
** Why do memory hierarchies work?
   - Because of locality, programs tend to access the data at level k more often than they access the data at level k + 1.
   - Thus, the storage at level k + 1 can be slower, and thus larger and cheaper per bit.
** Big Idea
   The memory hierarchy creates a large pool of storage that costs as much as the cheap storage near the bottom, but that serves data to programs at the rate of fast storage near the top.
** Hit
   Block looking for is in cache
** Miss
   Block looking for is not in cache
*** Cold miss
    Cold misses occur because the cache is empty.
*** Conflict miss
    - Most caches limit blocks at level k + 1 to a small subset (sometimes a singleton) of the block positions at level k. e.g. Block i at level k + 1 must be placed in block (i mod 4) at level k.
    - Conflict misses occur when the level k cache is large enough, but multiple data objects all map to the same level k block. e.g. Referencing blocks 0, 8, 0, 8, 0, 8, ... would miss every time.
*** Capacity miss
    Occurs when the set of active blocks (working set) is larger than the cache.
*** Placement policy
    determines where block goes
*** Replacement policy
    determines which block gets evicted
*** General Cache Organization (S, E, B)
    - S = 2^s sets
    - E = 2^e lines per set
    - B = 2^b bytes per cache block
    - C = S \times E \times B is the Cache size
**** Address of word
     - lower bits, b-bits are block offset
     - s-bits are index of set
     - remaining t-bits are tag
     - The cache take this address, and first extract the s-bits, and use it as an index to identify the set. If the block that contains this data word is in the cache, it is going to be in the set that is denoted by the set index. And then it checks the tag, check all lines in the set to see if any lines of the set has a matching tag, and check if the valid bit is turned on.
     - locate set
     - check if any line in set has matching tag
     - Yes + line valid, hit
      - locate data starting at offset
     - if the tag does not match, old line is evicted and replaced.
** Direct Mapped Cache
   E = 1, one line per set
** E-way Set Associative Cache
   E = 2, two lines per set
   - search for matching tag in the same set at the same time
   - once identify the match, locate data starting at offset
* Writing
** What to do on a write-hit?
   - write through :: write immediately to memory, always mirror the content of lower memory.
   - write back :: defer write to memory until replacement of line. Need a dirty bit to determine if line different from memory or not.
** What to do on a write-miss?
   - write-allocate :: load into cache, update line in cache. Good if more writes to the location follow.
   - No-write-allocate :: writes straightly to the memory, does not load into cache.
** Typical combination
   - write through + no-write-allocate
   - *write back + write-allocate*
* Cache performance Metrics
** Miss Rate
    - fraction of memory references not found in the cache (misses / accesses) = 1 - hit rate.
    - typical numbers in percentages
      - 3 - 10% for L1 cache
      - can be quite small (e.g. < 1%) for L2, depending on size, etc.
** Hit Time
   - time to deliver a line in the cache to the processor
     - includes time to determine whether the line is in the cache
   - typical numbers
     - 4 clock cycles for L1
     - 10 clock cycles for L2
** Miss Penalty
   - Additional time required because of a miss
     - typically 50 - 200 cycles for main memory
