#+TITLE: Compiling C code using GCC
#+AUTHOR: Yi Chen
#+EMAIL: reid@cs.wisc.edu
#+DATE: <2020-08-17 Mon>
#+tags[]: Compiler
#+keywords[]: C, GCC
#+category: notes
* Basic compilation using GCC
  #+BEGIN_SRC
  gcc matrix.c
  #+END_SRC
  This command outputs a executable binary named =a.out=, which can be executed in the shell by =./a.out=.
* Name the output binary file
  =a.out= may not be a great name for the your binary, and using =mv= to rename a file every time after compilation is tedious. The =-o= flag allows users to name the output binary.
  #+BEGIN_SRC
  gcc matrix.c -o matrix
  #+END_SRC
  Run the program by =./matrix=.
* Four Steps of compiling a c file to a executable binary
  1. Preprocessing
  2. Compiling 
  3. Assembly
  4. Linking
** Preprocessing 
   First step of a compilation process in which =header= files are swapped in, =macros= are substituted with its actual value, and =conditional compilation= is handled.
   The module which does the preprocessing is called preprocessor (=cpp=) whose input is a =c file= and output is a also a =c file=. To see the output of preprocessor, use the =-E= flag.
   #+BEGIN_SRC
   gcc matrix.c -E -o matrix.i
   #+END_SRC
   =matrix.i= contains the preprocessed code.
   #+BEGIN_SRC c
   // original code
   #include <stdlib.h>
   #include <stdio.h>

   typedef struct matrix_container {
       int row;
       int col;
       int **matrix;
   } Matrix;
   // preprocessed code
   # 422 "/usr/local/Cellar/gcc/10.1.0/lib/gcc/10/gcc/x86_64-apple-darwin19/10. 1.0/include-fixed/stdio.h" 2 3 4
   # 3 "matrix.c" 2


   # 4 "matrix.c"
   typedef struct matrix_container {
       int row;
       int col;
       int **matrix;
   } Matrix;
   #+END_SRC
   It can be seen that there is no more =#include= in the preprocessed file.
** Compiling
   Second step of a compilation process. The =compiler= (=cc1=) takes a preprocessed c file as an input and outputs a =.s= assembly program which contains the assembly code of the target machine.
   For example, my machine has an =intel= CPU. Therefore, the assembly program generated by the =compiler= (=cc1=) is in =x86-64= instruction set. Adding the =-m32= flag forces the compiler to generate =IA-32= assembly code.
   #+BEGIN_SRC
   gcc matrix.c -S -o matrix.s
   #+END_SRC
   output, content of matrix.s
   #+BEGIN_SRC x86-64
 L1$pb:
     subl    $12, %esp
     leal    lC0-L1$pb(%ebx), %eax
     pushl   %eax
     call    _puts
     addl    $16, %esp
     movl    $0, -12(%ebp)
     jmp L2
 L5:
     movl    $0, -16(%ebp)
     jmp L3
 L4:
     movl    8(%ebp), %eax
   #+END_SRC
** Assembling
   The =assemblar= (=as=) converts the assembly program to the relocatable object program, which is a binary but non-executable file. The reason why the binary cannot be executed is that assembly code for functions like =printf()= that is not written by you is not included.
   #+BEGIN_SRC
   gcc matrix.c -c -o matrix.o
   #+END_SRC
** Linking
   The =linker= (=ld=) gathers all relocatable files and combines them into a single executable binary file. It takes relocatable object files as input and output the final executable binary. It can be seen that the output of =linker= is larger than the output of =assemblar=, which does not include binary of other relocatable object files. There is no special flag for the =linker=.
   =matrix=, the executable binary, is larger than =matrix.o= (13128 > 3772).
   #+BEGIN_SRC
   -rwxr-xr-x  1 yichen  13128 Jul 30 23:32 matrix
   -rw-r--r--  1 yichen   3772 Jul 31 02:49 matrix.o
   #+END_SRC
* Other flags 
** -Wall
   Output all warnings. If I introduce a unused variable
   #+BEGIN_SRC c
    int main(void) {
        Matrix *matrices[2];
        for (int i = 0; i < 2; i++)
            matrices[i] = create_matrix();
        
        Matrix *result = multiply_matrix(matrices[0], matrices[1]);
        print_matrix(result);

        Matrix *mat; // unused variable

        free_matrix(result);
        free_matrix(matrices[0]);
        free_matrix(matrices[1]);
        return 0;
    }
   #+END_SRC
   compiling without =-Wall= flag, =GCC= does not have any output
   #+BEGIN_SRC
   ➜  matrix_hw gcc-10 matrix.c -o matrix
   ➜  matrix_hw
   #+END_SRC
   compiling with =-Wall= flag, =GCC= outputs a warning message
   #+BEGIN_SRC
   ➜  matrix_hw gcc-10 matrix.c -o matrix -Wall
   matrix.c: In function 'main':
   matrix.c:106:13: warning: unused variable 'mat' [-Wunused-variable]
     106 |     Matrix *mat;
         |             ^~~
   #+END_SRC
** -D
   -D [marco name]=[marco value] is equivalent to adding #define [marco name]=[macro value] to the source code.
   #+BEGIN_SRC c
int main(void) {
    Matrix *matrices[SIZE];
    for (int i = 0; i < SIZE; i++)
        matrices[i] = create_matrix();
    
    Matrix *result = multiply_matrix(matrices[0], matrices[1]);
    print_matrix(result);

    free_matrix(result);
    free_matrix(matrices[0]);
    free_matrix(matrices[1]);
    return 0;
}
   #+END_SRC
   The source code does not define =SIZE=. Hence, compiling without =-D= flag results an error.
   #+BEGIN_SRC
matrix.c: In function 'main':
matrix.c:99:22: error: 'SIZE' undeclared (first use in this function)
   99 |     Matrix *matrices[SIZE];
      |                      ^~~~
matrix.c:99:22: note: each undeclared identifier is reported only once for each function it appears in
   #+END_SRC
   Using the =-D= flag.
   #+BEGIN_SRC
   gcc-10 matrix.c -o matrix -D SIZE=2
   #+END_SRC
** -I
   =-I [dir]= adding extra header directory. =GCC= finds header files in the current directory or in =usr/include/=. Compiling the source code that includes header file that is in other directory results an error.
   #+BEGIN_SRC c
#include "matrix_op.h"
#define SIZE 2

int main(void) {
    Matrix *matrices[SIZE];
    for (int i = 0; i < SIZE; i++)
        matrices[i] = create_matrix();
    
    Matrix *result = multiply_matrix(matrices[0], matrices[1]);
    print_matrix(result);

    free_matrix(result);
    free_matrix(matrices[0]);
    free_matrix(matrices[1]);
    return 0;
}
   #+END_SRC
   =matrix_op.h= is not in =.= nor =usr/include=. It is in =./include=.
   #+BEGIN_SRC
   ➜  matrix_hw ls
   include     matrix      matrix.c
   ➜  matrix_hw ls include
   matrix_op.h
   #+END_SRC
   Compile the code results an error.
   #+BEGIN_SRC
   ➜  matrix_hw gcc-10 matrix.c matrix_op.c -o matrix
   matrix.c:1:10: fatal error: matrix_op.h: No such file or directory
       1 | #include "matrix_op.h"
         |          ^~~~~~~~~~~~~
   compilation terminated.
   matrix_op.c:3:10: fatal error: matrix_op.h: No such file or directory
       3 | #include "matrix_op.h"
         |          ^~~~~~~~~~~~~
   compilation terminated.
   #+END_SRC
   To compile it, add =-I [header dir]=.
   #+BEGIN_SRC
   matrix_hw gcc-10 matrix.c matrix_op.c -o matrix -I./include
   #+END_SRC
** -g 
   With =-g=, =GCC= compiles code with debug information, which is helpful when using debugger like =GDB= or =LLDB=.
   Setting breakpoints using filename and line number in =LLDB=, with binary that compiled without =-g= flag.
   #+BEGIN_SRC
   (lldb) b matrix.c:9
   Breakpoint 1: no locations (pending).
   WARNING:  Unable to resolve breakpoint to any actual locations.
   #+END_SRC
   Setting breakpoints using filename and line number in =LLDB=, with binary that compiled with =-g= flag.
   #+BEGIN_SRC
   (lldb) b matrix.c:9
   Breakpoint 1: where = matrix`main + 48 at matrix.c:9:22, address = 0x0000000100000724
   #+END_SRC
   It is more easier to debug, setting breakpoints, for example, with binary that compiled with =-g= flag.
* Optimization
  To see the optimization results, I wrote a program that does matrix multiplication of different size of matrices. Each run of the program is going to output the time it takes to finish the job. Then, I use a python script to run the program for 100 times, and calculate the mean, standard deviation, and total time. Since $N = 100$ is greater than 30, the sampling distribution is normal.
  | Flag | Average time (sec) | Standard Deviation | Compilation Time |
  |------+--------------------+--------------------+------------------|
  | None |            0.55726 |           0.035869 |            0.195 |
  | -O   |           0.200644 |           0.006497 |            0.212 |
  | -O2  |           0.079052 |           0.002817 |            0.286 |
  | -O3  |           0.077760 |           0.003685 |            0.477 |
  It can be seen that program compiled with =-O= flag is running significantly faster than program compiled without optimization flag.
  And program compiled with =-O2= is running significantly faster than program compiled with =-O1= flag.
  Moreover, the compilation time increases as more optimizations are applied.
** Significance test on the running time difference between the program compiled with -O2 and -O3 
   Test at $\alpha = 0.01$
   \begin{align*}
   H_0: \mu_1 = \mu_2 \\
   H_1: \mu_1 > \mu_2
   \end{align*}
   where $\mu_1$ is the true mean of running time of program compiled with =-O2= flag and $\mu_2$ is the true mean of running time of program compiled with =-O3= flag.

   \begin{align*}
   z &= \frac{\bar{x_1} - \bar{x_2}}{\sqrt{\frac{\sigma^2_1}{n_1} + \frac{\sigma^2_2}{n_2}}}\\
     &= \frac{0.079052 - 0.077760}{\sqrt{\frac{0.002817^2}{100} + \frac{0.003685^2}{100}}} \\
     &=	\frac{0.001292}{0.000464} \\
     &= 2.78
   \end{align*}
   Since $z = 2.78$ is greater than =2.575=, we reject the $H_0$. There is enough evidence showing that the matrix program compiled with =-O3= flag has significant shorter running time than the program compiled with =-O2= flag.
** Code, Script, and Results
  Test code:
  #+BEGIN_SRC c
    struct timeval tic, toc;
    gettimeofday(&tic, NULL);
    for (int i = 0; i < 100; i++) {
	Matrix *A = dummy_matrix(i, i * 5);
	Matrix *B = dummy_matrix(i * 5, i);

	multiply_matrix(A, B);

	free_matrix(A);
	free_matrix(B);
    }
    gettimeofday(&toc, NULL);
    printf("%lu", (toc.tv_sec - tic.tv_sec) * 1000000 + toc.tv_usec - tic.tv_usec);
  #+END_SRC
  Test script:
  #+BEGIN_SRC python
import os
import math
import subprocess

N = 100
results = []
for i in range(0, N):
    result = subprocess.check_output('./matrix', shell=True)
    result = int(result) / 1000000
    results.append(result)

TOTAL = sum(results)
MEAN = TOTAL / N

def process(x):
    return (x - MEAN) ** 2
VAR = sum(list(map(process, results))) / N
SD = math.sqrt(VAR)


print("-" * 10, "Result", "-" * 10)
print("n = %d, sum = %f" % (N, TOTAL))
print("mean = %f" % MEAN)
print("standard deviation = %f" % SD)
print(results)
  #+END_SRC
  Result without optimization flag
  #+BEGIN_SRC
---------- Result ----------
n = 100, sum = 55.726015
mean = 0.557260
standard deviation = 0.035869
  #+END_SRC
  Result with =-O= flag
  #+BEGIN_SRC
---------- Result ----------
n = 100, sum = 20.064405
mean = 0.200644
standard deviation = 0.006497
  #+END_SRC
  Result with =-O2= flag
  #+BEGIN_SRC
---------- Result ----------
n = 100, sum = 7.905217
mean = 0.079052
standard deviation = 0.002817
  #+END_SRC
  Result with =-O3= flag
  #+BEGIN_SRC
---------- Result ----------
n = 100, sum = 7.776048
mean = 0.077760
standard deviation = 0.003685
  #+END_SRC
* Different ways of performing matrix multiplication 
  [fn:1]
** jki
   #+BEGIN_SRC c
for (int j = 0; j < B->col; j++) {
    for (int k = 0; k < B->row; k++) {
	int r = B->matrix[k][j];
	for (int i = 0; i < A->row; i++) {
	    C->matrix[i][j] += A->matrix[i][k] * r;
	}
    }
}
   #+END_SRC
   This program has the worst performance since it has the worst spatial locality. Suppose the cache can only hold a row of the matrix. Each inner iteration of the innermost loop would lead to a cache miss since; each iteration of the second-most-inner loop too would lead to a cache miss. A cache miss requires CPU to fetch data from memory via bus, which is time consuming comparing to using cache data.
** kij
   #+BEGIN_SRC c
for (int k = 0; k < A->col; k++) {
    for (int i = 0; i < C->row; i++) {
	int r = A->matrix[i][k];
	for (int j = 0; j < B->col; j++) {
	    C->matrix[i][j] += r * B->matrix[k][j];
	}
    }
}
   #+END_SRC
   This way of performing matrix multiplication has the best performance since the stride size is smaller and the program takes the advantages of both spatial and temporal locality.
** ijk
   #+BEGIN_SRC c
for (int i = 0; i < C->row; i++) {
    for (int j = 0; j < C->col; j++) {
	for (int k = 0; k < A->col; k++) {
	    C->matrix[i][j] += A->matrix[i][k] * B->matrix[k][j];
	}
    }
}
   #+END_SRC
   This program has the moderate performance. 
** Comparison
Here is a plot comparing the average task completion time of 50 runs of each ways of performing matrix multiplication. It can be seen that generally, =kij= has the best performance. It advantage is especially notable when the dimension of matrix is increasing, as more L1 cache is used.
   [[./different_ways.png]]
* Different optimization flags on different sizes of matrix
  [[./different_optimization.png]]
  The plot indicates that =-03= has the best performance over all the other optimization rules. As the dimension of the matrix involved in the multiplication process increases, the advantage of =-O3= is more noticeable.
  The reason that =-O3= has the best performance is that =-O3= attempts to vectorize loops, which are used abundantly in the operation of matrix multiplication. It uses more advanced instruction set that has better arithmetic performance.
  It can be seen from the following image that =-O2= flag together with =ftree-vectorize= achieve the similar performance of =-O3=. This phenomenon indicates that vectorization has a great impact on program's performance.
  [[vec-o2.png]]
  Moreover, according to =GCC=, line =112= is optimized.
  #+BEGIN_SRC
➜  code gcc-10 matrix_op.c main.c -o matrix_vec -ftree-vectorize -O2 -mavx -fopt-info-vec-optimized
matrix_op.c:112:3: optimized: loop vectorized using 16 byte vectors
matrix_op.c:112:3: optimized:  loop versioned for vectorization because of possible aliasing
  #+END_SRC
  This line is corresponding to the following =C= code
  #+BEGIN_SRC c
  for (int j = 0; j < B->col; j++)
  #+END_SRC
  Which is an essential part to the matrix multiplication.
[fn:1] https://blog.csdn.net/haolexiao/article/details/65936158
* -ftree-vectorize
As mentioned above, the most significant optimization in =-O3= for the program is =-ftree-vectorize=.
Roughly speaking, when =-ftree-vectorize= is activated, =GCC= will try to convert normal loop into loop that utilizes =SIMD= built-in functions. The =tree-vectorizer= is going to analyze the loops and then transform the vectorizable loops into the designated form. Each loop and each statement in will be attached by =loop_vec_info= and =stmt_vec_info=.
When transforming loop, the program is going to scan every statements inside the loop and create a corresponding vector for everything needed to be vectorized.
