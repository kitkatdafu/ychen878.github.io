<!doctype html><html lang=en-us><head><link rel=preload href=/lib/font-awesome/webfonts/fa-brands-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/font-awesome/webfonts/fa-regular-400.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/font-awesome/webfonts/fa-solid-900.woff2 as=font type=font/woff2 crossorigin=anonymous><link rel=preload href=/lib/JetBrainsMono/web/woff2/JetBrainsMono-Regular.woff2 as=font type=font/woff2 crossorigin=anonymous><script type=text/javascript src=https://latest.cactus.chat/cactus.js></script>
<link rel=stylesheet href=https://latest.cactus.chat/style.css type=text/css><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><title>MCMC | mrr1vfe</title><link rel=canonical href=https://www.mrr1vfe.io/posts/mcmc/><meta name=description content="This is my website"><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="all,follow"><meta name=googlebot content="index,follow,snippet,archive"><meta property="og:title" content="MCMC"><meta property="og:description" content="About MCMC The esitmation of posterior probability distributions using a stochastic process known as Markov chain Monte Carlo (MCMC).
We will be able to sample directly from the posterior. MCMC requires more computation (takes longer to complete estimation). Metropolis algorithm The metropolis algorihtm works whenever the probability of proposing a jump to $B$ from $A$ is equal to the probability of proposing $A$ from $B$, when the proposal distribution is symmetric."><meta property="og:type" content="article"><meta property="og:url" content="https://www.mrr1vfe.io/posts/mcmc/"><meta property="article:section" content="posts"><meta name=twitter:card content="summary"><meta name=twitter:title content="MCMC"><meta name=twitter:description content="About MCMC The esitmation of posterior probability distributions using a stochastic process known as Markov chain Monte Carlo (MCMC).
We will be able to sample directly from the posterior. MCMC requires more computation (takes longer to complete estimation). Metropolis algorithm The metropolis algorihtm works whenever the probability of proposing a jump to $B$ from $A$ is equal to the probability of proposing $A$ from $B$, when the proposal distribution is symmetric."><link rel=stylesheet href=https://www.mrr1vfe.io/css/styles.4c2b9aa1d874d6766f554b2d404e8fd62ab4761f51ee9b3f358d12e81e7fa43a1b4378db995bc1926bbe5ed98c060be5e7bd4f2470504cf94f22b4b3a74e62b6.css integrity="sha512-TCuaodh01nZvVUstQE6P1iq0dh9R7ps/NY0S6B5/pDobQ3jbmVvBkmu+XtmMBgvl571PJHBQTPlPIrSzp05itg=="><!--[if lt IE 9]><script src=https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js></script>
<script src=https://oss.maxcdn.com/respond/1.4.2/respond.min.js></script><![endif]--><link rel=icon type=image/png href=https://www.mrr1vfe.io/images/favicon.ico></head><body class="max-width mx-auto px3 ltr"><div class="content index py4"><div id=header-post><a id=menu-icon href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=menu-icon-tablet href=#><i class="fas fa-bars fa-lg"></i></a>
<a id=top-icon-tablet href=# onclick='$("html, body").animate({scrollTop:0},"fast")' style=display:none aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg"></i></a>
<span id=menu><span id=nav><ul><li><a href=/>Home</a></li><li><a href=/posts>Writings</a></li><li><a href=/about>About</a></li></ul></span><br><span id=actions><ul><li><a class=icon href=https://www.mrr1vfe.io/posts/bayesian/ aria-label=Next><i class="fas fa-chevron-right" aria-hidden=true onmouseover='$("#i-next").toggle()' onmouseout='$("#i-next").toggle()'></i></a></li><li><a class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up" aria-hidden=true onmouseover='$("#i-top").toggle()' onmouseout='$("#i-top").toggle()'></i></a></li><li><a class=icon href=# aria-label=Share><i class="fas fa-share-alt" aria-hidden=true onmouseover='$("#i-share").toggle()' onmouseout='$("#i-share").toggle()' onclick='return $("#share").toggle(),!1'></i></a></li></ul><span id=i-prev class=info style=display:none>Previous post</span>
<span id=i-next class=info style=display:none>Next post</span>
<span id=i-top class=info style=display:none>Back to top</span>
<span id=i-share class=info style=display:none>Share post</span></span><br><div id=share style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f" aria-label=Facebook><i class="fab fa-facebook" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&text=MCMC" aria-label=Twitter><i class="fab fa-twitter" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&title=MCMC" aria-label=Linkedin><i class="fab fa-linkedin" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&is_video=false&description=MCMC" aria-label=Pinterest><i class="fab fa-pinterest" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=MCMC&body=Check out this article: https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f" aria-label=Email><i class="fas fa-envelope" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&title=MCMC" aria-label=Pocket><i class="fab fa-get-pocket" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&title=MCMC" aria-label=reddit><i class="fab fa-reddit" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&name=MCMC&description=About%20MCMC%20The%20esitmation%20of%20posterior%20probability%20distributions%20using%20a%20stochastic%20process%20known%20as%20Markov%20chain%20Monte%20Carlo%20%28MCMC%29.%0aWe%20will%20be%20able%20to%20sample%20directly%20from%20the%20posterior.%20MCMC%20requires%20more%20computation%20%28takes%20longer%20to%20complete%20estimation%29.%20Metropolis%20algorithm%20The%20metropolis%20algorihtm%20works%20whenever%20the%20probability%20of%20proposing%20a%20jump%20to%20%24B%24%20from%20%24A%24%20is%20equal%20to%20the%20probability%20of%20proposing%20%24A%24%20from%20%24B%24%2c%20when%20the%20proposal%20distribution%20is%20symmetric." aria-label=Tumblr><i class="fab fa-tumblr" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&t=MCMC" aria-label="Hacker News"><i class="fab fa-hacker-news" aria-hidden=true></i></a></li></ul></div><div id=toc><nav id=TableOfContents><ul><li><a href=#headline-1>About MCMC</a><ul><li><a href=#headline-2>Metropolis algorithm</a></li><li><a href=#headline-3>Metropolis-Hastings algorithm</a></li><li><a href=#headline-4>Gibbs sampling</a><ul><li><a href=#headline-5>High-dimensional problems</a></li></ul></li></ul></li></ul></nav></div></span></div><article class=post itemscope itemtype=http://schema.org/BlogPosting><header><h1 class=posttitle itemprop="name headline">MCMC</h1><div class=meta><div class=postdate><time datetime="0001-01-01 00:00:00 +0000 UTC" itemprop=datePublished>0001-01-01</time></div><div class=article-read-time><i class="far fa-clock"></i>
1 minute read</div></div></header><div class=content itemprop=articleBody><div id=outline-container-headline-1 class=outline-2><h2 id=headline-1>About MCMC</h2><div id=outline-text-headline-1 class=outline-text-2><ul><li>The esitmation of posterior probability distributions using a stochastic process</li></ul><p>known as Markov chain Monte Carlo (MCMC).</p><ul><li>We will be able to sample directly from the posterior.</li><li>MCMC requires more computation (takes longer to complete estimation).</li></ul><div id=outline-container-headline-2 class=outline-3><h3 id=headline-2>Metropolis algorithm</h3><div id=outline-text-headline-2 class=outline-text-3><p>The metropolis algorihtm works whenever the probability of proposing a jump to
$B$ from $A$ is equal to the probability of proposing $A$ from $B$, when the
proposal distribution is symmetric.</p></div></div><div id=outline-container-headline-3 class=outline-3><h3 id=headline-3>Metropolis-Hastings algorithm</h3><div id=outline-text-headline-3 class=outline-text-3><ul><li>It allows asymmetric proposals.</li><li>Easier to handle parameters that have boundaries.</li><li>Generates savvy proposals that explore the posterior more efficiently. (We can
acquire an equally good image of the posterior distribution in fewer steps.)</li></ul></div></div><div id=outline-container-headline-4 class=outline-3><h3 id=headline-4>Gibbs sampling</h3><div id=outline-text-headline-4 class=outline-text-3><ul><li>A variant of the Metropolis-Hastings algorithm.</li><li><p>It uses adaptive proposals</p><ul><li>The distribution of proposed parameter values adjusts itself intelligently, depending upon the prameter values at the moment.</li><li>Adaptive proposals use conjugate paris, particular combinations of prior
distributions and likelihoods.</li><li>Conjugate pairs have analytical solutions for the posterior distribution of
an individual parameter.</li></ul></li></ul><div id=outline-container-headline-5 class=outline-4><h4 id=headline-5>High-dimensional problems</h4><div id=outline-text-headline-5 class=outline-text-4><ul><li>Some conjugate priors are actually pathological in shape.</li><li><p>As models become more complex and contain hundreds or thousands or tens of
thousands of parameters, both Metropolis and Gibbs sampling become shockeling
inefficnet.</p><ul><li>They tend to get stuck in small regions of the posterior for potentially a
long time.</li></ul></li><li><p>When the number of parameters is large, two or more parameters are highly
correlated with one another in the posterior samples.</p><ul><li>High correlation means a narrow ridge of high probability combinations, and
both Metropolis and Gibbs make too many dumb proposals of where to go
next. So they get stuck.</li></ul></li><li>When the number of dimension is high, the smapled points are in a thin, high
dimensional shell very far from the mode. This shell create very hard paths
fro a sampler to follow.</li></ul></div></div></div></div></div></div></div></article><div id=footer-post-container><div id=footer-post><div id=nav-footer style=display:none><ul><li><a href=/>Home</a></li><li><a href=/posts>Writings</a></li><li><a href=/about>About</a></li></ul></div><div id=toc-footer style=display:none><nav id=TableOfContents><ul><li><a href=#headline-1>About MCMC</a><ul><li><a href=#headline-2>Metropolis algorithm</a></li><li><a href=#headline-3>Metropolis-Hastings algorithm</a></li><li><a href=#headline-4>Gibbs sampling</a><ul><li><a href=#headline-5>High-dimensional problems</a></li></ul></li></ul></li></ul></nav></div><div id=share-footer style=display:none><ul><li><a class=icon href="http://www.facebook.com/sharer.php?u=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f" aria-label=Facebook><i class="fab fa-facebook fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://twitter.com/share?url=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&text=MCMC" aria-label=Twitter><i class="fab fa-twitter fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.linkedin.com/shareArticle?url=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&title=MCMC" aria-label=Linkedin><i class="fab fa-linkedin fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://pinterest.com/pin/create/bookmarklet/?url=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&is_video=false&description=MCMC" aria-label=Pinterest><i class="fab fa-pinterest fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="mailto:?subject=MCMC&body=Check out this article: https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f" aria-label=Email><i class="fas fa-envelope fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://getpocket.com/save?url=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&title=MCMC" aria-label=Pocket><i class="fab fa-get-pocket fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://reddit.com/submit?url=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&title=MCMC" aria-label=reddit><i class="fab fa-reddit fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="http://www.tumblr.com/share/link?url=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&name=MCMC&description=About%20MCMC%20The%20esitmation%20of%20posterior%20probability%20distributions%20using%20a%20stochastic%20process%20known%20as%20Markov%20chain%20Monte%20Carlo%20%28MCMC%29.%0aWe%20will%20be%20able%20to%20sample%20directly%20from%20the%20posterior.%20MCMC%20requires%20more%20computation%20%28takes%20longer%20to%20complete%20estimation%29.%20Metropolis%20algorithm%20The%20metropolis%20algorihtm%20works%20whenever%20the%20probability%20of%20proposing%20a%20jump%20to%20%24B%24%20from%20%24A%24%20is%20equal%20to%20the%20probability%20of%20proposing%20%24A%24%20from%20%24B%24%2c%20when%20the%20proposal%20distribution%20is%20symmetric." aria-label=Tumblr><i class="fab fa-tumblr fa-lg" aria-hidden=true></i></a></li><li><a class=icon href="https://news.ycombinator.com/submitlink?u=https%3a%2f%2fwww.mrr1vfe.io%2fposts%2fmcmc%2f&t=MCMC" aria-label="Hacker News"><i class="fab fa-hacker-news fa-lg" aria-hidden=true></i></a></li></ul></div><div id=actions-footer><a id=menu-toggle class=icon href=# onclick='return $("#nav-footer").toggle(),!1' aria-label=Menu><i class="fas fa-bars fa-lg" aria-hidden=true></i> Menu</a>
<a id=toc-toggle class=icon href=# onclick='return $("#toc-footer").toggle(),!1' aria-label=TOC><i class="fas fa-list fa-lg" aria-hidden=true></i> TOC</a>
<a id=share-toggle class=icon href=# onclick='return $("#share-footer").toggle(),!1' aria-label=Share><i class="fas fa-share-alt fa-lg" aria-hidden=true></i> share</a>
<a id=top style=display:none class=icon href=# onclick='$("html, body").animate({scrollTop:0},"fast")' aria-label="Top of Page"><i class="fas fa-chevron-up fa-lg" aria-hidden=true></i> Top</a></div></div></div><footer id=footer><div class=footer-left>Copyright &copy; 2022 Yi Chen</div><div class=footer-right><nav><ul><li><a href=/>Home</a></li><li><a href=/posts>Writings</a></li><li><a href=/about>About</a></li></ul></nav></div></footer></div></body><link rel=stylesheet href=/lib/font-awesome/css/all.min.css><script src=/lib/jquery/jquery.min.js></script>
<script src=/js/main.js></script>
<script src=/js/code-copy.js></script>
<script>MathJax={tex:{inlineMath:[["$","$"],["\\(","\\)"]]},svg:{fontCache:"global"}}</script><script type=text/javascript id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script></html>