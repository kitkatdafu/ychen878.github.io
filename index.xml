<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>mrr1vfe</title><link>https://www.mrr1vfe.io/</link><description>Recent content on mrr1vfe</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><copyright>Reid Chen</copyright><lastBuildDate>Tue, 19 Oct 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://www.mrr1vfe.io/index.xml" rel="self" type="application/rss+xml"/><item><title>About me</title><link>https://www.mrr1vfe.io/about/</link><pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate><guid>https://www.mrr1vfe.io/about/</guid><description>I am a graduate student in the ECE department at the University of Wisconsin-Madison, advised by Prof. Ramya Korlakai Vinayak.
CV
my girlfriend is 招财.</description></item><item><title>K-means in Python</title><link>https://www.mrr1vfe.io/posts/k-means/</link><pubDate>Tue, 19 Oct 2021 00:00:00 +0000</pubDate><guid>https://www.mrr1vfe.io/posts/k-means/</guid><description>K-means There are two major steps in the K-means algorithm. The first one is to calculate the representatives (centroids) of a given partition. The second one is to find the partition based on the representatives.
Inputs Suppose we have a dataset looks like this:
1dataset = np.array([[5, 6], 2 [6, 5], 3 [0, 1], 4 [1, 0], 5 [3, 3]]) Each row in this dataset matrix is an observation and each column in this matrix represents a feature.</description></item></channel></rss>