<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Yi Chen</title><link>https://ychen878.github.io/</link><description>Recent content on Yi Chen</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Thu, 02 Mar 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://ychen878.github.io/index.xml" rel="self" type="application/rss+xml"/><item><title>Nuclear Norm via SDP</title><link>https://ychen878.github.io/notes/nuclear-norm-sdp/</link><pubDate>Thu, 02 Mar 2023 00:00:00 +0000</pubDate><guid>https://ychen878.github.io/notes/nuclear-norm-sdp/</guid><description>&lt;p>:PROPERTIES:
:CUSTOM_ID: matrix-norm
:END:&lt;/p>
&lt;h1 id="matrix-norms">Matrix norms&lt;/h1>
&lt;p>Given a matrix $X \in \mathbb{R}^{m \times n}$, $\sigma_{i}(X)$ denotes the $i$-th largest singular value of $X$ and is equal to the square root of the $i$-th largest eigenvalue of $XX&amp;rsquo;$. The rank of $X$, denoted as $\mathrm{rank}(X) = r$ is the number of non-zero singular values.&lt;/p>
&lt;h2 id="inner-product">Inner Product&lt;/h2>
&lt;p>Given $X, Y \in \mathbb{R}^{m \times n}$, the inner product between $X$ and $Y$, denoted by $\langle X, Y\rangle$, is defined as
$$
\langle X, Y \rangle := \mathrm{Tr}(X&amp;rsquo;Y) = \sum_{i=1}^m \sum_{j=1}^n X_{ij}Y_{ij} = \mathrm{Tr}(Y&amp;rsquo;X).
$$&lt;/p></description></item><item><title>LP Duality</title><link>https://ychen878.github.io/notes/lp-duality/</link><pubDate>Tue, 28 Feb 2023 00:00:00 +0000</pubDate><guid>https://ychen878.github.io/notes/lp-duality/</guid><description>&lt;h1 id="estimating-lp-bounds">Estimating LP bounds&lt;/h1>
&lt;p>Given an optimization problem
$$
\begin{align}
\max_{f, s} &amp;amp;\quad 12f + 9s \
\st &amp;amp;\quad 4f + 2s \leq 4800 \
&amp;amp;\quad f + s \leq 1750 \
&amp;amp;\quad 0 \leq f \leq 1000 \
&amp;amp;\quad 0 \leq s \leq 1500 \
\end{align}
$$
Suppose the maximum profit is $p^\star$. How can we bound $p^\star$? The lower bound of $p^\star$ can be found by picking any feasible point (since maximization). For example,
${f=0, s=0}$ is feasible. Therefore, $p^\star \geq 12f + 9s = 0$. Since any feasible point yields a lower bound of $p^\star$ and $p^\star$ itself is yielded by an feasible point, then finding the largest lower bound of $p^\star$ is equivalent to solving the LP.&lt;/p></description></item><item><title>RPC</title><link>https://ychen878.github.io/notes/rpc/</link><pubDate>Sat, 25 Feb 2023 22:51:15 -0600</pubDate><guid>https://ychen878.github.io/notes/rpc/</guid><description>&lt;h1 id="networks">Networks&lt;/h1>
&lt;p>Network Interface Controllers (NICs) can connect a computer to different physical mediums, such as Ethernet and Wi-Fi. Every NIC in the world has a unique MAC (media access control) address. It consists of 48 bits. Therefore, there are 28 trillion possible MAC addresses. Some devices randomly change their MAC address for privacy.&lt;/p>
&lt;p>You can use command &lt;code>ifconfig&lt;/code> to check you network interface controller and its corresponding MAC address. There exists virtual interfaces as well. For example, &lt;code>lo&lt;/code>, the loopback device, is a virtual interface. It connects your computer to a mini network containing just your computer.&lt;/p></description></item><item><title>Docker</title><link>https://ychen878.github.io/notes/docker/</link><pubDate>Sat, 25 Feb 2023 22:49:32 -0600</pubDate><guid>https://ychen878.github.io/notes/docker/</guid><description>&lt;h1 id="virtualization">Virtualization&lt;/h1>
&lt;p>Virtualization is the illusion of private resources, provided by the software. We have virtual memory, virtual machine (hardware), virtual machine (languages), virtual operating system (container).&lt;/p>
&lt;ul>
&lt;li>Each process using a virtual address space is not aware of other processes using memory (illusion of private memory).&lt;/li>
&lt;li>Virtualized resources include CPU, RAM, disks, network devices, etc. VMs rarely use all their allocated resources, so overbooking is possible. If each program is deployed to a different VM, operating system overheads dominate.&lt;/li>
&lt;li>JVM or PVM runs Java Bytecode and Python Bytecode. Programs written in Java and Python are compiled to their corresponding byte code instead of a specific machine code.&lt;/li>
&lt;li>Virtual operating systems, or a containers, are run on a some flavor of Linux. You can have a container of Ubuntu and a container on Debian (but not Windows, since they are running on top of Linux). Containers are more efficient than virtual machines, but less flexible.&lt;/li>
&lt;/ul>
&lt;p>Containers and Virtual Machines are Sandboxes.&lt;/p></description></item><item><title>Perceptron Learning Algorithm</title><link>https://ychen878.github.io/notes/pla/</link><pubDate>Wed, 30 Nov 2022 00:00:00 +0000</pubDate><guid>https://ychen878.github.io/notes/pla/</guid><description>&lt;p>
Given a dataset
\(\mathcal{D} = \{(\vec{x}_1, y_1), \cdots, (\vec{x}_N, y_N)\}\) and a
hypothesis set \(\mathcal{H}\), our learning algorithm \(\mathcal{A}\)
tries to learn a function \(g \in \mathcal{H}\) that approximates the
underlying, true function \(f: \mathcal{X} \to \mathcal{Y}\), which
generates the points in \(\mathcal{D}\).&lt;/p>
&lt;div id="outline-container-credit-card-approve-problem" class="outline-3">
&lt;h3 id="credit-card-approve-problem">
Credit Card Approve Problem
&lt;/h3>
&lt;div id="outline-text-credit-card-approve-problem" class="outline-text-3">
&lt;p>Given a customer who is applying for a credit card, we want to build a
system that determines if we should grant the application or not based
on the customer&amp;#39;s information such as age, annual salary, year in job,
etc. The bank&amp;#39;s historical credit approval data can be seen as a dataset
\(\mathcal{D} = \{(\vec{x}_i, y_i)\}_{i=1}^N\)where each
\(\vx_i \in \mathcal{X}\) and each represents a customer. There is a
target function \(f: \mathcal{X} \to \mathcal{Y}\) that gives \(\vx\)&amp;#39;s
credit behavior \(f(\vec{x}) = y\). Each \(\vx\) is a multidimensional
vector where each component is a feature (age, for example). Our
learning algorithm \(\mathcal{A}\) considers a hypothesis class
\(\mathcal{H}\) and takes the dataset \(\mathcal{D}\) and tries to give
a function \(g \in \mathcal{H}\) so that \(g\) performs similar to
\(f\). We will use \(g\) as our system of approving credit card.&lt;/p></description></item><item><title>Clustering</title><link>https://ychen878.github.io/notes/clustering/</link><pubDate>Sat, 08 Oct 2022 00:00:00 +0000</pubDate><guid>https://ychen878.github.io/notes/clustering/</guid><description>&lt;p>
In unsupervised learning, there are no labels associated with features.
Generally speaking, the ultimate goal of unsupervised learning is to
find patterns and structures that help us to better understand data.
Sometimes, we also use unsupervised learning to model a distribution.
But we generally will not make predictions.&lt;/p>
&lt;p>
There are 3 types of clustering 1. Partitional (centroid,
graph-theoretic, spectral) 1. Hierarchical (agglomerative, divisive) 2.
Bayesian (decision-based, non-parametric)&lt;/p>
&lt;div id="outline-container-partitional-clustering" class="outline-3">
&lt;h3 id="partitional-clustering">
Partitional Clustering
&lt;/h3>
&lt;div id="outline-text-partitional-clustering" class="outline-text-3">
&lt;div id="outline-container-k-means" class="outline-4">
&lt;h4 id="k-means">
\(k\)-means
&lt;/h4>
&lt;div id="outline-text-k-means" class="outline-text-4">
&lt;p>\(k\)-means is a type of partitional centroid-based clustering
algorithm. The algorithm is described as follows: 1. Randomly pick \(k\)
cluster centers; 2. Find the closest center for each point; 3. Update
cluster centers by computing centroids; 4. While not converging, jump to
step 2.&lt;/p></description></item><item><title>K-means in Python</title><link>https://ychen878.github.io/notes/k-means/</link><pubDate>Tue, 19 Oct 2021 00:00:00 +0000</pubDate><guid>https://ychen878.github.io/notes/k-means/</guid><description>&lt;p>There are two major steps in the K-means algorithm. The first one is to
calculate the representatives (centroids) of a given partition. The
second one is to find the partition based on the representatives.&lt;/p>
&lt;div id="outline-container-inputs" class="outline-3">
&lt;h3 id="inputs">
Inputs
&lt;/h3>
&lt;div id="outline-text-inputs" class="outline-text-3">
&lt;p>Suppose we have a dataset looks like this:&lt;/p>
&lt;div class="src src-python">
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>dataset &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([[&lt;span style="color:#ae81ff">5&lt;/span>, &lt;span style="color:#ae81ff">6&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#ae81ff">6&lt;/span>, &lt;span style="color:#ae81ff">5&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> [&lt;span style="color:#ae81ff">3&lt;/span>, &lt;span style="color:#ae81ff">3&lt;/span>]])&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>
&lt;/div>
&lt;p>
Each row in this dataset matrix is an observation and each column in
this matrix represents a feature. So, in this example, we have 5 points
from a plane. And we define partition in the following way:&lt;/p></description></item><item><title/><link>https://ychen878.github.io/projects/archive/frontend/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://ychen878.github.io/projects/archive/frontend/</guid><description>&lt;!DOCTYPE html>
&lt;html lang="en">
&lt;head>
 &lt;meta charset="UTF-8">
 &lt;meta name="viewport" content="width=device-width, initial-scale=1.0">
 &lt;title>TTS WebSocket Test Client&lt;/title>
 &lt;style>
 body {
 font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
 max-width: 800px;
 margin: 0 auto;
 padding: 20px;
 background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
 min-height: 100vh;
 color: white;
 }
 
 .container {
 background: rgba(255, 255, 255, 0.1);
 backdrop-filter: blur(10px);
 border-radius: 20px;
 padding: 30px;
 box-shadow: 0 8px 32px rgba(31, 38, 135, 0.37);
 border: 1px solid rgba(255, 255, 255, 0.18);
 }
 
 h1 {
 text-align: center;
 margin-bottom: 30px;
 background: linear-gradient(45deg, #fff, #f0f0f0);
 -webkit-background-clip: text;
 -webkit-text-fill-color: transparent;
 font-size: 2.5em;
 }
 
 .input-group {
 margin: 20px 0;
 }
 
 label {
 display: block;
 margin-bottom: 8px;
 font-weight: 600;
 }
 
 input, textarea, select {
 width: 100%;
 padding: 12px;
 border: none;
 border-radius: 10px;
 background: rgba(255, 255, 255, 0.2);
 color: white;
 font-size: 16px;
 }
 
 input::placeholder, textarea::placeholder {
 color: rgba(255, 255, 255, 0.7);
 }
 
 textarea {
 height: 120px;
 resize: vertical;
 }
 
 .button-group {
 display: flex;
 gap: 15px;
 margin: 20px 0;
 }
 
 button {
 flex: 1;
 padding: 12px 24px;
 border: none;
 border-radius: 10px;
 font-size: 16px;
 font-weight: 600;
 cursor: pointer;
 transition: all 0.3s ease;
 }
 
 button:hover {
 transform: translateY(-2px);
 }
 
 .connect-btn {
 background: linear-gradient(45deg, #4CAF50, #45a049);
 color: white;
 }
 
 .disconnect-btn {
 background: linear-gradient(45deg, #f44336, #da190b);
 color: white;
 }
 
 .speak-btn {
 background: linear-gradient(45deg, #2196F3, #0b7dda);
 color: white;
 }
 
 .stop-btn {
 background: linear-gradient(45deg, #FF9800, #e68900);
 color: white;
 }
 
 .status {
 padding: 15px;
 margin: 20px 0;
 border-radius: 10px;
 text-align: center;
 font-weight: 600;
 }
 
 .status.connected {
 background: rgba(76, 175, 80, 0.3);
 border: 2px solid #4CAF50;
 }
 
 .status.disconnected {
 background: rgba(244, 67, 54, 0.3);
 border: 2px solid #f44336;
 }
 
 .status.speaking {
 background: rgba(33, 150, 243, 0.3);
 border: 2px solid #2196F3;
 animation: pulse 2s infinite;
 }
 
 @keyframes pulse {
 0%, 100% { opacity: 1; }
 50% { opacity: 0.7; }
 }
 
 .captions {
 background: rgba(0, 0, 0, 0.5);
 padding: 20px;
 border-radius: 10px;
 min-height: 100px;
 max-height: 200px;
 margin: 20px 0;
 font-family: 'Courier New', monospace;
 font-size: 18px;
 line-height: 1.5;
 overflow-y: auto;
 overflow-x: hidden;
 word-wrap: break-word;
 word-break: break-word;
 white-space: pre-wrap;
 position: relative;
 }
 
 .current-char {
 background: #FFD700;
 color: #000;
 padding: 2px 4px;
 border-radius: 3px;
 animation: highlight 0.5s ease;
 display: inline;
 }
 
 @keyframes highlight {
 from { background: #FF6B6B; }
 to { background: #FFD700; }
 }
 
 .caption-char {
 display: inline;
 }
 
 .log {
 background: rgba(0, 0, 0, 0.3);
 padding: 15px;
 border-radius: 10px;
 max-height: 200px;
 overflow-y: auto;
 font-family: 'Courier New', monospace;
 font-size: 14px;
 }
 
 .log-entry {
 margin: 5px 0;
 padding: 5px;
 border-left: 3px solid #2196F3;
 padding-left: 10px;
 }
 
 .log-entry.timing {
 border-left-color: #FF9800;
 color: #FFD700;
 }
 
 .log-entry.performance {
 border-left-color: #4CAF50;
 color: #90EE90;
 }
 &lt;/style>
&lt;/head>
&lt;body>
 &lt;div class="container">
 &lt;h1>ðŸŽ¤ TTS WebSocket Test Client&lt;/h1>
 
 &lt;div class="input-group">
 &lt;label for="serverUrl">WebSocket Server URL:&lt;/label>
 &lt;input type="text" id="serverUrl" value="ws://localhost:8765" placeholder="ws://localhost:8765">
 &lt;/div>
 
 &lt;div class="button-group">
 &lt;button id="connectBtn" class="connect-btn">Connect&lt;/button>
 &lt;button id="disconnectBtn" class="disconnect-btn" disabled>Disconnect&lt;/button>
 &lt;/div>
 
 &lt;div id="status" class="status disconnected">Disconnected&lt;/div>
 
 &lt;div class="input-group">
 &lt;label for="textInput">Text to Speak:&lt;/label>
 &lt;textarea id="textInput" placeholder="Enter text here... Try: 'Hello, this is a test of the text-to-speech system!'">&lt;/textarea>
 &lt;/div>
 
 &lt;div class="button-group">
 &lt;button id="speakBtn" class="speak-btn" disabled>Speak Text&lt;/button>
 &lt;button id="stopBtn" class="stop-btn" disabled>Stop&lt;/button>
 &lt;/div>
 
 &lt;div class="input-group">
 &lt;label>Real-time Captions:&lt;/label>
 &lt;div id="captions" class="captions">Captions will appear here...&lt;/div>
 &lt;/div>
 
 &lt;div class="input-group">
 &lt;label>Debug Log:&lt;/label>
 &lt;div id="log" class="log">&lt;/div>
 &lt;/div>
 &lt;/div>

 &lt;script>
 class TTSWebSocketClient {
 constructor() {
 this.socket = null;
 this.audioContext = null;
 this.isConnected = false;
 this.isSpeaking = false;
 this.currentAudio = null;
 this.audioQueue = [];
 this.isPlayingQueue = false;
 this.currentCharIndex = 0;
 this.currentText = '';
 this.totalCaptionText = '';
 this.captionOffset = 0;
 
 // Timing tracking
 this.firstChunkReceived = false;
 this.chunkTimings = [];
 this.totalChunks = 0;
 this.chunksReceived = 0;
 
 this.initUI();
 this.initAudioContext();
 }
 
 initUI() {
 this.connectBtn = document.getElementById('connectBtn');
 this.disconnectBtn = document.getElementById('disconnectBtn');
 this.speakBtn = document.getElementById('speakBtn');
 this.stopBtn = document.getElementById('stopBtn');
 this.status = document.getElementById('status');
 this.captions = document.getElementById('captions');
 this.log = document.getElementById('log');
 this.textInput = document.getElementById('textInput');
 this.serverUrl = document.getElementById('serverUrl');
 
 this.connectBtn.addEventListener('click', () => this.connect());
 this.disconnectBtn.addEventListener('click', () => this.disconnect());
 this.speakBtn.addEventListener('click', () => this.speakText());
 this.stopBtn.addEventListener('click', () => this.stopSpeaking());
 }
 
 async initAudioContext() {
 try {
 this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
 this.logMessage('Audio context initialized');
 } catch (error) {
 this.logMessage('Error initializing audio context: ' + error.message);
 }
 }
 
 connect() {
 const url = this.serverUrl.value;
 this.logMessage('Connecting to: ' + url);
 
 try {
 this.socket = new WebSocket(url);
 
 this.socket.onopen = () => {
 this.isConnected = true;
 this.updateStatus('connected', 'Connected');
 this.logMessage('Connected to WebSocket server');
 
 // Send initialization message
 this.socket.send(JSON.stringify({ text: ' ', flush: false }));
 };
 
 this.socket.onmessage = (event) => {
 this.handleMessage(event.data);
 };
 
 this.socket.onclose = () => {
 this.isConnected = false;
 this.updateStatus('disconnected', 'Disconnected');
 this.logMessage('Disconnected from server');
 };
 
 this.socket.onerror = (error) => {
 this.logMessage('WebSocket error: ' + error);
 };
 
 } catch (error) {
 this.logMessage('Connection error: ' + error.message);
 }
 }
 
 disconnect() {
 if (this.socket) {
 this.socket.send(JSON.stringify({ text: '', flush: false }));
 this.socket.close();
 }
 this.stopSpeaking();
 }
 
 async handleMessage(data) {
 try {
 const receiveTime = performance.now();
 const message = JSON.parse(data);
 
 if (message.audio &amp;&amp; message.alignment) {
 // Track timing for first chunk
 if (!this.firstChunkReceived) {
 this.logTimingMessage(`First audio chunk received`, 'timing');
 this.firstChunkReceived = true;
 }
 
 // Track individual chunk timing
 this.chunksReceived++;
 const chunkTiming = {
 chunkNumber: this.chunksReceived,
 receivedAt: receiveTime,
 audioLength: message.audio.length,
 charCount: message.alignment.chars ? message.alignment.chars.length : 0,
 serverLatency: message.latency || null
 };
 this.chunkTimings.push(chunkTiming);
 
 // Log chunk info with server latency if available
 let chunkInfo = `Chunk ${this.chunksReceived}: ${chunkTiming.charCount} chars, ${(chunkTiming.audioLength / 1024).toFixed(1)}KB audio`;
 if (message.latency !== undefined) {
 chunkInfo += `, ${message.latency.toFixed(1)}ms server latency`;
 }
 this.logTimingMessage(chunkInfo, 'timing');
 
 // Add to queue instead of playing immediately
 this.audioQueue.push({
 audio: message.audio,
 alignment: message.alignment,
 receivedAt: receiveTime
 });
 
 // Start playing queue if not already playing
 if (!this.isPlayingQueue) {
 this.playNextInQueue();
 }
 }
 
 } catch (error) {
 this.logMessage('Error handling message: ' + error.message);
 }
 }
 
 async playNextInQueue() {
 if (this.audioQueue.length === 0) {
 this.isPlayingQueue = false;
 this.updateStatus('connected', 'Connected');
 this.isSpeaking = false;
 
 // Log final performance statistics
 this.logPerformanceStats();
 return;
 }
 
 this.isPlayingQueue = true;
 const audioItem = this.audioQueue.shift(); // Remove first item from queue
 await this.playAudio(audioItem.audio, audioItem.alignment);
 }
 
 async playAudio(audioBase64, alignment) {
 try {
 const playStartTime = performance.now();
 
 // Stop any currently playing audio
 if (this.currentAudio) {
 this.currentAudio.stop();
 this.currentAudio = null;
 }
 
 // Decode base64 audio
 const binaryString = atob(audioBase64);
 const bytes = new Uint8Array(binaryString.length);
 for (let i = 0; i &lt; binaryString.length; i++) {
 bytes[i] = binaryString.charCodeAt(i);
 }
 
 // Convert PCM16 to Float32Array for Web Audio API
 const audioData = new Float32Array(bytes.length / 2);
 const view = new DataView(bytes.buffer);
 
 for (let i = 0; i &lt; audioData.length; i++) {
 const sample = view.getInt16(i * 2, true); // little endian
 audioData[i] = sample / 32768.0; // Convert to [-1, 1]
 }
 
 // Create audio buffer
 const audioBuffer = this.audioContext.createBuffer(1, audioData.length, 44100);
 audioBuffer.copyToChannel(audioData, 0);
 
 // Create audio source
 const source = this.audioContext.createBufferSource();
 source.buffer = audioBuffer;
 source.connect(this.audioContext.destination);
 
 // Handle alignment for captions (adjust for cumulative text)
 if (alignment.chars &amp;&amp; alignment.char_start_times_ms) {
 this.showCaptions(alignment, this.captionOffset);
 // Update caption offset for next chunk
 this.captionOffset += alignment.chars.length;
 }
 
 // Calculate audio processing time
 const processingTime = performance.now() - playStartTime;
 const audioDurationMs = (audioData.length / 44100) * 1000;
 
 // Set up audio completion handler BEFORE starting
 source.onended = () => {
 this.currentAudio = null;
 // Play next item in queue after current finishes
 setTimeout(() => {
 this.playNextInQueue();
 }, 50); // Small delay to prevent audio glitches
 };
 
 // Start playing
 source.start();
 this.currentAudio = source;
 
 this.logTimingMessage(`Audio decoded and started (${processingTime.toFixed(1)}ms processing, ${audioDurationMs.toFixed(0)}ms duration)`, 'performance');
 
 } catch (error) {
 this.logMessage('Error playing audio: ' + error.message);
 // Continue with next item even if this one failed
 setTimeout(() => {
 this.playNextInQueue();
 }, 100);
 }
 }
 
 logPerformanceStats() {
 if (this.chunkTimings.length === 0) return;
 
 const totalChars = this.chunkTimings.reduce((sum, chunk) => sum + chunk.charCount, 0);
 const avgChunkSize = this.chunkTimings.reduce((sum, chunk) => sum + chunk.audioLength, 0) / this.chunkTimings.length;
 
 // Calculate average server latency if available
 const chunksWithLatency = this.chunkTimings.filter(chunk => chunk.serverLatency !== null);
 const avgServerLatency = chunksWithLatency.length > 0 
 ? chunksWithLatency.reduce((sum, chunk) => sum + chunk.serverLatency, 0) / chunksWithLatency.length
 : null;
 
 this.logTimingMessage(`ðŸŽ¯ PERFORMANCE SUMMARY:`, 'performance');
 this.logTimingMessage(` Chunks received: ${this.chunkTimings.length}`, 'performance');
 this.logTimingMessage(` Total characters: ${totalChars}`, 'performance');
 this.logTimingMessage(` Avg chunk size: ${(avgChunkSize / 1024).toFixed(1)}KB`, 'performance');
 
 if (avgServerLatency !== null) {
 this.logTimingMessage(` Avg server latency: ${avgServerLatency.toFixed(1)}ms`, 'performance');
 this.logTimingMessage(` Server generation rate: ${(totalChars / (avgServerLatency * this.chunkTimings.length / 1000)).toFixed(1)} chars/sec`, 'performance');
 }
 
 // Reset timing data for next request
 this.chunkTimings = [];
 this.chunksReceived = 0;
 this.firstChunkReceived = false;
 this.requestStartTime = null;
 }
 
 showCaptions(alignment, offset = 0) {
 const chars = alignment.chars;
 const startTimes = alignment.char_start_times_ms;
 
 if (!chars || !startTimes) return;
 
 // Build cumulative caption text
 this.totalCaptionText += chars.join('');
 
 // Create HTML for all caption text so far
 let captionHTML = '';
 for (let i = 0; i &lt; this.totalCaptionText.length; i++) {
 const char = this.totalCaptionText[i];
 // Handle different character types properly
 if (char === ' ') {
 captionHTML += `&lt;span id="char-${i}" class="caption-char">&amp;nbsp;&lt;/span>`;
 } else if (char === '\n') {
 captionHTML += `&lt;span id="char-${i}" class="caption-char">&lt;br>&lt;/span>`;
 } else {
 const escapedChar = char.replace(/[&lt;>&amp;"]/g, function(match) {
 switch(match) {
 case '&lt;': return '&amp;lt;';
 case '>': return '&amp;gt;';
 case '&amp;': return '&amp;amp;';
 case '"': return '&amp;quot;';
 default: return match;
 }
 });
 captionHTML += `&lt;span id="char-${i}" class="caption-char">${escapedChar}&lt;/span>`;
 }
 }
 
 this.captions.innerHTML = captionHTML;
 
 // Animate character highlighting for this chunk only
 startTimes.forEach((startTime, index) => {
 setTimeout(() => {
 const globalCharIndex = offset + index;
 const charElement = document.getElementById(`char-${globalCharIndex}`);
 if (charElement) {
 // Remove previous highlighting
 document.querySelectorAll('.current-char').forEach(el => {
 el.classList.remove('current-char');
 });
 
 // Add current highlighting
 charElement.classList.add('current-char');
 
 // Scroll to keep current character visible within the captions box
 const captionsBox = this.captions;
 const charRect = charElement.getBoundingClientRect();
 const boxRect = captionsBox.getBoundingClientRect();
 
 // Check if character is outside visible area
 if (charRect.bottom > boxRect.bottom || charRect.top &lt; boxRect.top) {
 charElement.scrollIntoView({ 
 behavior: 'smooth', 
 block: 'center'
 });
 }
 }
 }, startTime);
 });
 }
 
 speakText() {
 const text = this.textInput.value.trim();
 if (!text || !this.isConnected) return;
 
 // Clear previous session state
 this.stopSpeaking();
 this.totalCaptionText = '';
 this.captionOffset = 0;
 this.audioQueue = [];
 
 // Reset timing tracking
 this.firstChunkReceived = false;
 this.chunkTimings = [];
 this.chunksReceived = 0;
 
 this.currentText = text;
 this.isSpeaking = true;
 this.updateStatus('speaking', 'Speaking...');
 this.logMessage(`ðŸ“¤ Starting TTS request: "${text.substring(0, 50)}${text.length > 50 ? '...' : ''}" (${text.length} chars)`);
 
 // Resume audio context if suspended
 if (this.audioContext.state === 'suspended') {
 this.audioContext.resume();
 }
 
 // Send text in chunks for streaming
 const chunkSize = 50;
 const totalChunks = Math.ceil(text.length / chunkSize);
 this.totalChunks = totalChunks;
 
 this.logTimingMessage(`Sending ${totalChunks} text chunks to server...`, 'timing');
 
 for (let i = 0; i &lt; text.length; i += chunkSize) {
 const chunk = text.substring(i, i + chunkSize);
 const isLast = i + chunkSize >= text.length;
 
 setTimeout(() => {
 if (this.socket &amp;&amp; this.isConnected) {
 this.socket.send(JSON.stringify({
 text: chunk,
 flush: isLast
 }));
 }
 }, i / chunkSize * 100); // Small delay between chunks
 }
 }
 
 stopSpeaking() {
 // Stop current audio
 if (this.currentAudio) {
 this.currentAudio.stop();
 this.currentAudio = null;
 }
 
 // Clear audio queue
 this.audioQueue = [];
 this.isPlayingQueue = false;
 this.isSpeaking = false;
 
 // Reset caption state
 this.totalCaptionText = '';
 this.captionOffset = 0;
 
 // Reset timing data
 this.chunkTimings = [];
 this.chunksReceived = 0;
 this.firstChunkReceived = false;
 
 if (this.isConnected) {
 this.updateStatus('connected', 'Connected');
 } else {
 this.updateStatus('disconnected', 'Disconnected');
 }
 
 this.captions.innerHTML = 'Captions will appear here...';
 this.logMessage('ðŸ›‘ Speech stopped');
 }
 
 updateStatus(type, message) {
 this.status.className = `status ${type}`;
 this.status.textContent = message;
 
 // Update button states
 this.connectBtn.disabled = this.isConnected;
 this.disconnectBtn.disabled = !this.isConnected;
 this.speakBtn.disabled = !this.isConnected || this.isSpeaking;
 this.stopBtn.disabled = !this.isSpeaking;
 }
 
 logMessage(message, type = 'normal') {
 const timestamp = new Date().toLocaleTimeString();
 const logEntry = document.createElement('div');
 logEntry.className = `log-entry ${type}`;
 logEntry.textContent = `[${timestamp}] ${message}`;
 
 this.log.appendChild(logEntry);
 this.log.scrollTop = this.log.scrollHeight;
 
 // Keep only last 100 log entries
 while (this.log.children.length > 100) {
 this.log.removeChild(this.log.firstChild);
 }
 }
 
 logTimingMessage(message, type = 'timing') {
 this.logMessage(`â±ï¸ ${message}`, type);
 }
 }
 
 // Initialize client when page loads
 window.addEventListener('load', () => {
 const client = new TTSWebSocketClient();
 });
 &lt;/script>
&lt;/body>
&lt;/html></description></item></channel></rss>